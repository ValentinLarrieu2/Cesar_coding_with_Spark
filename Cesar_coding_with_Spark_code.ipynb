{"cells":[{"cell_type":"code","source":["#####Rendu Hadoop project\n\n#Full example 1: the guess is done joining tables with the language specified, takes some time and need the language\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql.functions import UserDefinedFunction\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql import functions as F\n\nLANGUAGE=\"english\"\n\n#########################################################################\n#Function which Reads the file generated by hadoop and create the dataframe with 2 column: the letter and the number of letters\ndef readHadoopFileDf(path):\n  rddFreq=sc.textFile(path).map(lambda line: line.split('\\t')) #we read the haddop result\n  rddMap = rddFreq.map(lambda scmr:(scmr[0],int(scmr[1])))\n  #We convert it to dataframe\n  dfFreq = rddMap.toDF([\"letter\",\"countLetter\"])#we create the dataframe\n  return dfFreq\n\ndfFreq=readHadoopFileDf(\"/FileStore/tables/4gv5en6u1509544751327/part_r_00000-b65ee\")#We read the file returned by hadoop and create the corresponding dataframe\ndfFreqEisH=readHadoopFileDf(\"/FileStore/tables/part_r_00003-dc956\")\ndfFreqCiphered3=readHadoopFileDf(\"/FileStore/tables/part_r_00000_CharFreqFullyCiphered3-29f14\")\n\n#Function which add a column to a dataframe with the same string on each element\ndef addFixedColumnToDf(dataframe,columnName,content):\n  dataframe=dataframe.withColumn(columnName, lit(content))#we add the language column\n  return dataframe\n\ndfFreq=addFixedColumnToDf(dfFreq,\"language\",LANGUAGE) #We add a column to the dataframe containing \"english\"\ndfFreqEisH=addFixedColumnToDf(dfFreqEisH,\"language\",LANGUAGE) #We add a column to the dataframe containing \"english\"\ndfCiphered3=addFixedColumnToDf(dfFreqCiphered3,\"language\",LANGUAGE) #We add a column to the dataframe containing \"english\"\n\ndfFreq.show()\ndfFreqEisH.show()\ndfFreqCiphered3.show()\n\n#This function generates a dataframe containing 2 column: the country & the most used letter in that language\ndef generateMostFreqLetterByCountryDF():\n  set = [('english','e'),('french','e'),('spanish','e'),('dutch','e'),('swedish','e'),('danish','e'),('portuguese','a'),('italian','a')]\n  rdd = sc.parallelize(set)\n  dfLang = rdd.map(lambda x: (x[0], x[1]))\n  dfLang = dfLang.toDF([\"language\",\"mostFrequentLetter\"])\n  return dfLang\n\ndfLang=generateMostFreqLetterByCountryDF() #We generate the table containing the letter the most used in the languages we selected (can be extanded)\ndfLang.show(10)\n\n\n#######################################################################First method, takes a lot of times (because of the joins), was optimised by the guess function\n#We select the max value and put it in a dataframe with the letter the most represented in that language\nspark.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")\ndef joinLangAndOutputDF(dfMR,dfTableLang):\n  frequencyResult=dfMR.groupby(\"language\").agg(F.max(\"countLetter\")).toDF(\"language\",\"countLetter\") #create a dataframe corresponding to the max value of count\n  dfFreqMax=dfMR.join(frequencyResult, [\"countLetter\",\"language\"])\n  dfResult = dfTableLang.join(dfFreqMax, [\"language\"])\n  return dfResult\n\ncharDistDf=joinLangAndOutputDF(dfFreq,dfLang)\ncharDistDf2=joinLangAndOutputDF(dfFreqEisH,dfLang)\ncharDistDf3=joinLangAndOutputDF(dfCiphered3,dfLang)\n\n#########################\n\n\n#this function can code and decode,if the entry is letter it return the letter + SHIFT letter (in a circular list) \n# else it returns the letter given first. It implements the Cesar coding\ndef cypherLetter(x,value):\n  SHIFT=value\n  if ((ord(x) <= ord(\"Z\")) and (ord(x) >= ord(\"A\"))):  # we test if it is an upercase letter\n    if ((ord(x) + SHIFT) <= ord(\"Z\")) and ((ord(x) + SHIFT) >= ord(\"A\")):  # the new letter stay in the interval\n      return chr(ord(x) + SHIFT)\n    else: # if it is outside of the interval\n      if ((ord(x) + SHIFT) > ord(\"Z\")):  # the new letter is outside the right part of the interval\n        return chr(ord(\"A\") -1 + (ord(x) + SHIFT - ord(\"Z\")))\n      else:  # the new letter is outside the left part of the interval\n        return chr(ord(\"Z\") +1 + (ord(x) + SHIFT - ord(\"A\")))\n\n  if ((ord(x) <= ord(\"z\")) and (ord(x) >= ord(\"a\"))):\n    if ((ord(x) + SHIFT) <= ord(\"z\")) and ((ord(x) + SHIFT) >= ord(\"a\")):\n      return chr(ord(x) + SHIFT)\n    else:  # It is outside of the interval\n      if ((ord(x) + SHIFT) > ord(\"z\")):  # the new letter is outside the right part of the interval\n        return chr(ord(\"a\") -1 + (ord(x) + SHIFT - ord(\"z\")))\n      else: # the new letter is outside the left part of the interval\n        return chr(ord(\"z\") +1 + (ord(x) + SHIFT - ord(\"a\")))\n  else:  # it is not a letter\n    return x\n                   \n    \ndef cypherDataframeColumn(columnName,value,dataframe):\n  udf = UserDefinedFunction(lambda x: cypherLetter(x,value), StringType())\n  new_df = dataframe.select(*[udf(column).alias(columnName) if column == columnName else column for column in dataframe.columns])\n  return new_df\n\n#returns the number of char separing the reference from the other char (ex : getCharDiff(\"a\",\"c\") = -2)\ndef getCharDiff(charMessage,charReference): \n  return ord(charMessage)-ord(charReference)\n\n\ncharFreqText=charDistDf.select('letter').collect()[0].letter #We get the letter the most present in our text\ncharFreqLang=charDistDf.select('mostFrequentLetter').collect()[0].mostFrequentLetter #We get the letter the most present normally in that language\ncypheringKey=getCharDiff(charFreqText,charFreqLang) #We compute the \"distance\" between the most frequent letter in our language and our text = cyphering key\n\ncharFreqText2=charDistDf2.select('letter').collect()[0].letter #We get the letter the most present in our text\ncharFreqLang2=charDistDf2.select('mostFrequentLetter').collect()[0].mostFrequentLetter #We get the letter the most present normally in that language\ncypheringKey2=getCharDiff(charFreqText2,charFreqLang2) #We compute the \"distance\" between the most frequent letter in our language and our text = cyphering key\n\ncharFreqText3=charDistDf3.select('letter').collect()[0].letter #We get the letter the most present in our text\ncharFreqLang3=charDistDf3.select('mostFrequentLetter').collect()[0].mostFrequentLetter #We get the letter the most present normally in that language\ncypheringKey3=getCharDiff(charFreqText3,charFreqLang3) #We compute the \"distance\" between the most frequent letter in our language and our text = cyphering key\n\nprint(\"LETTER DIFFERENCE FOR ORIGINAL TEXT\")\nprint(cypheringKey)\nprint(\"LETTER DIFFERENCE FOR MODIFIED TEXT\")\nprint(cypheringKey2)\nprint(\"LETTER DIFFERENCE FOR FULLY MODIFIED TEXT\")\nprint(cypheringKey3)\n\n###########################################We test our cyphering/deciphering method on columns of the dataframe\nresult2= cypherDataframeColumn(\"letter\",4,charDistDf)#we cypher a column\nresult2.show()\n\ndiffRefChar=getCharDiff(\"a\",\"c\")\nprint(diffRefChar)\n\nresult3= cypherDataframeColumn(\"letter\",-diffRefChar,result2)#we decypher that column\nresult3.show()\n\nprint(\"Original Object\")\ncharDistDf2.show()\nresult3= cypherDataframeColumn(\"letter\",-cypheringKey2,charDistDf2)#we decypher that column\nprint(\"Object decyphered\")\nresult3.show()\n###########################################"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#Example 2: guessing language and key\n\n#returns the number of char separing the reference from the other char (ex : getCharDiff(\"a\",\"c\") = -2)\ndef getCharDiff(charMessage,charReference): \n  return ord(charMessage)-ord(charReference)\n\ndef readHadoopFileDf(path):\n  rddFreq=sc.textFile(path).map(lambda line: line.split('\\t')) #we read the haddop result\n  rddMap = rddFreq.map(lambda scmr:(scmr[0],int(scmr[1])))\n  #We convert it to dataframe\n  dfFreq = rddMap.toDF([\"letter\",\"countLetter\"])#we create the dataframe\n  return dfFreq\n\ndfFreq=readHadoopFileDf(\"/FileStore/tables/4gv5en6u1509544751327/part_r_00000-b65ee\")#We read the file returned by hadoop and create the corresponding dataframe\ndfFreqEisH=readHadoopFileDf(\"/FileStore/tables/part_r_00003-dc956\")\ndfFreqCiphered3=readHadoopFileDf(\"/FileStore/tables/part_r_00000_CharFreqFullyCiphered3-29f14\")\n\n#Function wich returns the language and the cyphering key of the dataframe (based on the 4 most frequent letters here). If no language is detected precisly, it returns \"NoLanguage\" as the language and 0 as the cyphering key\ndef guessLanguageAndCypheringKey(dataframe):\n  resultLangKey = [(\"NoLanguage\"), ('0')]\n\n  dataframe=dataframe.sort(dataframe.countLetter, ascending=False)#We sort the letters by descending order\n  #display(dfFreqCiphered3)\n\n  #We get the 4 most used letters. Here we compute the 10 first one as we have them all in our list but we will only use 4 of them (we can scale it up to 10 then)\n  charLetter11=dataframe.select('letter').collect()[0].letter #We get the letter the most present in our text\n  charLetter12=dataframe.select('letter').collect()[1].letter \n  charLetter13=dataframe.select('letter').collect()[2].letter \n  charLetter14=dataframe.select('letter').collect()[3].letter \n  charLetter15=dataframe.select('letter').collect()[4].letter \n  charLetter16=dataframe.select('letter').collect()[5].letter \n  charLetter17=dataframe.select('letter').collect()[6].letter \n  charLetter18=dataframe.select('letter').collect()[7].letter \n  charLetter19=dataframe.select('letter').collect()[8].letter \n  charLetter110=dataframe.select('letter').collect()[9].letter \n\n  #We create our object storing the most used letters by order in each of the 8 languages we selected (can easily be extended)\n  set = [('english','e','t','a','o','i','n','s','h','r','d'),('french','e','s','a','i','t','n','r','u','o','l'),('spanish','e','a','o','s','r','n','i','d','l','t'),('dutch','e','n','a','t','i','r','o','d','s','l'),('german','e','n','s','r','i','a','t','d','h','u'),('danish','e','r','n','t','a','i','d','s','l','o'),('portuguese','a','e','o','s','r','i','d','m','n','t'),('italian','e','a','i','o','n','l','r','t','s','c')]\n  rdd = sc.parallelize(set)\n\n  \"\"\"\n  #if we want to compute the full distances regarding the 10 most used letter in our languages\n  rddLang = rdd.map(lambda x: (x[0], getCharDiff(charLetter11,x[1]), getCharDiff(charLetter12,x[2]), getCharDiff(charLetter13,x[3]), getCharDiff(charLetter14,x[4]), getCharDiff(charLetter15,x[5]), getCharDiff(charLetter16,x[6]),getCharDiff(charLetter17,x[7]),getCharDiff(charLetter18,x[8]),getCharDiff(charLetter19,x[9]),getCharDiff(charLetter110,x[10])))\n  dfTableLang = rddLang.toDF([\"Language\",\"Letter1\",\"Letter2\",\"Letter3\",\"Letter4\",\"Letter5\",\"Letter6\",\"Letter7\",\"Letter8\",\"Letter9\",\"Letter10\"])\n  #display(dfTableLang)\n\n  #if we want to compute the distances regarding only the 4 most used letters\n  rddLang4=rdd.map(lambda x: (x[0], getCharDiff(charLetter11,x[1]), getCharDiff(charLetter12,x[2]), getCharDiff(charLetter13,x[3]), getCharDiff(charLetter14,x[4])))\n  dfTableLang4=rddLang4.toDF([\"Language\",\"Letter1\",\"Letter2\",\"Letter3\",\"Letter4\"])\n  #display(dfTableLang4)\n  \"\"\"\n\n  dfLanguageKey = rdd.map(lambda x: (x[0], (getCharDiff(charLetter11,x[1]) if (getCharDiff(charLetter11,x[1]) == getCharDiff(charLetter12,x[2]) and getCharDiff(charLetter12,x[2]) == getCharDiff(charLetter13,x[3]) and getCharDiff(charLetter13,x[3]) == getCharDiff(charLetter14,x[4])) else (-1000)))).toDF([\"language\",\"cypherKey\"])#if the distance between the most frequent letter by order by language is the same, we put a 1 it is that language. (if it is the same language the distance should be the same on each letter)\n\n  #the function getCharDiff can only return between -25 and 25 so puting -1000 as the default value ensure us that our element being not the good language won't be at first position when we sort them, that is to say the good\n  #language is in first position\n  dfLanguageKey=dfLanguageKey.sort(dfLanguageKey.cypherKey, ascending=False)#we sort our dataFrame\n  #display(dfLanguageKey)\n\n  languageGuessed=dfLanguageKey.select('language').collect()[0].language #we extract the language detected\n  cipheringKeyGuessed=dfLanguageKey.select('cypherKey').collect()[0].cypherKey #we extract the cypheringKey\n\n  #By default, if no language is detected precisly, the functions return a cyphering key of 0 and a language of \"NoLanguage\"\n  if (cipheringKeyGuessed!= -1000):\n    resultLangKey[0]=languageGuessed\n    resultLangKey[1]=cipheringKeyGuessed\n    \n  return (resultLangKey)\n\nlangCypherKeyListPlainText=guessLanguageAndCypheringKey(dfFreq)\nlangCypherKeyListEisH=guessLanguageAndCypheringKey(dfFreqEisH)\nlangCypherKeyListCipheredText3=guessLanguageAndCypheringKey(dfFreqCiphered3) #will contain the result of the guess: the language AND the cypheringKey\n\nprint(\"LETTER DIFFERENCE FOR ORIGINAL TEXT\")\nprint(langCypherKeyListPlainText[1])\nprint(\"LETTER DIFFERENCE FOR MODIFIED TEXT (E is H) => should return 0 since only one letter has been modified\")\nprint(langCypherKeyListEisH[1])\nprint(\"LETTER DIFFERENCE FOR FULLY MODIFIED TEXT\")\nprint(langCypherKeyListCipheredText3[1])\nprint(\"LANGUAGE DETECTED\")\nprint(langCypherKeyListCipheredText3[0])"],"metadata":{},"outputs":[],"execution_count":2}],"metadata":{"name":"CesarTest","notebookId":1644109540378890},"nbformat":4,"nbformat_minor":0}
