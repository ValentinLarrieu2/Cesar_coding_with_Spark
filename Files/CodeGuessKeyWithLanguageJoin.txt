#####Rendu Hadoop project

#Full example 1: the guess is done joining tables with the language specified, takes some time and need the language
from pyspark.sql.functions import lit
from pyspark.sql.functions import UserDefinedFunction
from pyspark.sql.types import StringType
from pyspark.sql import functions as F

LANGUAGE="english"

#########################################################################
#Function which Reads the file generated by hadoop and create the dataframe with 2 column: the letter and the number of letters
def readHadoopFileDf(path):
  rddFreq=sc.textFile(path).map(lambda line: line.split('\t')) #we read the haddop result
  rddMap = rddFreq.map(lambda scmr:(scmr[0],int(scmr[1])))
  #We convert it to dataframe
  dfFreq = rddMap.toDF(["letter","countLetter"])#we create the dataframe
  return dfFreq

dfFreq=readHadoopFileDf("/FileStore/tables/4gv5en6u1509544751327/part_r_00000-b65ee")#We read the file returned by hadoop and create the corresponding dataframe
dfFreqEisH=readHadoopFileDf("/FileStore/tables/part_r_00003-dc956")
dfFreqCiphered3=readHadoopFileDf("/FileStore/tables/part_r_00000_CharFreqFullyCiphered3-29f14")

#Function which add a column to a dataframe with the same string on each element
def addFixedColumnToDf(dataframe,columnName,content):
  dataframe=dataframe.withColumn(columnName, lit(content))#we add the language column
  return dataframe

dfFreq=addFixedColumnToDf(dfFreq,"language",LANGUAGE) #We add a column to the dataframe containing "english"
dfFreqEisH=addFixedColumnToDf(dfFreqEisH,"language",LANGUAGE) #We add a column to the dataframe containing "english"
dfCiphered3=addFixedColumnToDf(dfFreqCiphered3,"language",LANGUAGE) #We add a column to the dataframe containing "english"

dfFreq.show()
dfFreqEisH.show()
dfFreqCiphered3.show()

#This function generates a dataframe containing 2 column: the country & the most used letter in that language
def generateMostFreqLetterByCountryDF():
  set = [('english','e'),('french','e'),('spanish','e'),('dutch','e'),('swedish','e'),('danish','e'),('portuguese','a'),('italian','a')]
  rdd = sc.parallelize(set)
  dfLang = rdd.map(lambda x: (x[0], x[1]))
  dfLang = dfLang.toDF(["language","mostFrequentLetter"])
  return dfLang

dfLang=generateMostFreqLetterByCountryDF() #We generate the table containing the letter the most used in the languages we selected (can be extanded)
dfLang.show(10)


#######################################################################First method, takes a lot of times (because of the joins), was optimised by the guess function
#We select the max value and put it in a dataframe with the letter the most represented in that language
spark.conf.set("spark.sql.crossJoin.enabled", "true")
def joinLangAndOutputDF(dfMR,dfTableLang):
  frequencyResult=dfMR.groupby("language").agg(F.max("countLetter")).toDF("language","countLetter") #create a dataframe corresponding to the max value of count
  dfFreqMax=dfMR.join(frequencyResult, ["countLetter","language"])
  dfResult = dfTableLang.join(dfFreqMax, ["language"])
  return dfResult

charDistDf=joinLangAndOutputDF(dfFreq,dfLang)
charDistDf2=joinLangAndOutputDF(dfFreqEisH,dfLang)
charDistDf3=joinLangAndOutputDF(dfCiphered3,dfLang)

#########################


#this function can code and decode,if the entry is letter it return the letter + SHIFT letter (in a circular list) 
# else it returns the letter given first. It implements the Cesar coding
def cypherLetter(x,value):
  SHIFT=value
  if ((ord(x) <= ord("Z")) and (ord(x) >= ord("A"))):  # we test if it is an upercase letter
    if ((ord(x) + SHIFT) <= ord("Z")) and ((ord(x) + SHIFT) >= ord("A")):  # the new letter stay in the interval
      return chr(ord(x) + SHIFT)
    else: # if it is outside of the interval
      if ((ord(x) + SHIFT) > ord("Z")):  # the new letter is outside the right part of the interval
        return chr(ord("A") -1 + (ord(x) + SHIFT - ord("Z")))
      else:  # the new letter is outside the left part of the interval
        return chr(ord("Z") +1 + (ord(x) + SHIFT - ord("A")))

  if ((ord(x) <= ord("z")) and (ord(x) >= ord("a"))):
    if ((ord(x) + SHIFT) <= ord("z")) and ((ord(x) + SHIFT) >= ord("a")):
      return chr(ord(x) + SHIFT)
    else:  # It is outside of the interval
      if ((ord(x) + SHIFT) > ord("z")):  # the new letter is outside the right part of the interval
        return chr(ord("a") -1 + (ord(x) + SHIFT - ord("z")))
      else: # the new letter is outside the left part of the interval
        return chr(ord("z") +1 + (ord(x) + SHIFT - ord("a")))
  else:  # it is not a letter
    return x
                   
    
def cypherDataframeColumn(columnName,value,dataframe):
  udf = UserDefinedFunction(lambda x: cypherLetter(x,value), StringType())
  new_df = dataframe.select(*[udf(column).alias(columnName) if column == columnName else column for column in dataframe.columns])
  return new_df

#returns the number of char separing the reference from the other char (ex : getCharDiff("a","c") = -2)
def getCharDiff(charMessage,charReference): 
  return ord(charMessage)-ord(charReference)


charFreqText=charDistDf.select('letter').collect()[0].letter #We get the letter the most present in our text
charFreqLang=charDistDf.select('mostFrequentLetter').collect()[0].mostFrequentLetter #We get the letter the most present normally in that language
cypheringKey=getCharDiff(charFreqText,charFreqLang) #We compute the "distance" between the most frequent letter in our language and our text = cyphering key

charFreqText2=charDistDf2.select('letter').collect()[0].letter #We get the letter the most present in our text
charFreqLang2=charDistDf2.select('mostFrequentLetter').collect()[0].mostFrequentLetter #We get the letter the most present normally in that language
cypheringKey2=getCharDiff(charFreqText2,charFreqLang2) #We compute the "distance" between the most frequent letter in our language and our text = cyphering key

charFreqText3=charDistDf3.select('letter').collect()[0].letter #We get the letter the most present in our text
charFreqLang3=charDistDf3.select('mostFrequentLetter').collect()[0].mostFrequentLetter #We get the letter the most present normally in that language
cypheringKey3=getCharDiff(charFreqText3,charFreqLang3) #We compute the "distance" between the most frequent letter in our language and our text = cyphering key

print("LETTER DIFFERENCE FOR ORIGINAL TEXT")
print(cypheringKey)
print("LETTER DIFFERENCE FOR MODIFIED TEXT")
print(cypheringKey2)
print("LETTER DIFFERENCE FOR FULLY MODIFIED TEXT")
print(cypheringKey3)

###########################################We test our cyphering/deciphering method on columns of the dataframe
result2= cypherDataframeColumn("letter",4,charDistDf)#we cypher a column
result2.show()

diffRefChar=getCharDiff("a","c")
print(diffRefChar)

result3= cypherDataframeColumn("letter",-diffRefChar,result2)#we decypher that column
result3.show()

print("Original Object")
charDistDf2.show()
result3= cypherDataframeColumn("letter",-cypheringKey2,charDistDf2)#we decypher that column
print("Object decyphered")
result3.show()
###########################################